{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data.task_multi import multi\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "from task_embedding_GRU import RNN_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer(nn.Module):\n",
    "    def __init__(self, num, sigma = 1,hidden_dim=20, input_dim = 20):\n",
    "        super(layer, self).__init__()\n",
    "        self.num = num \n",
    "        self.sigma = sigma\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.center = nn.ParameterList([nn.Parameter(torch.zeros([input_dim])) for _ in range(num)])\n",
    "        self.transform = nn.ModuleList([nn.Linear(input_dim, hidden_dim) for _ in range(num)])\n",
    "    def forward(self, h):\n",
    "        #h -> b*p_num * hidden\n",
    "        #batch * p_num * hidden -> b * p_num * num\n",
    "        dis = []\n",
    "        for c in self.center:\n",
    "            distance = torch.sum((h - c.view(1,1,-1))**2, dim=-1)/(2.0 * self.sigma)#b*p_num\n",
    "            dis.append(distance)\n",
    "        dis = torch.stack(dis, dim = -1) #b*p_num*num\n",
    "        prob = F.softmax(-dis, dim = -1) #b * p * num\n",
    "        # b * p * num & b * p\n",
    "        all_hidden = []\n",
    "        for i in range(h.shape[1]):\n",
    "            hidden = h[:,i,:]\n",
    "            post = []\n",
    "            for linear in self.transform:\n",
    "                post_linear = linear(hidden)#b*after_linear_hidden\n",
    "                post.append(post_linear)\n",
    "            post = torch.stack(post, dim=1)#b * num * after_hidden\n",
    "            all_hidden.append(post)\n",
    "        all_hidden = torch.stack(all_hidden, dim=1)#b * p_num * num * after_hidden\n",
    "        all_hidden = torch.sum(prob.unsqueeze(dim=-1) * all_hidden, dim = 1)# b * num * after_hidden\n",
    "        return all_hidden\n",
    "    \n",
    "class clustering(nn.Module):\n",
    "    def __init__(self, layer_unit = [4,2,1]):\n",
    "        super(clustering, self).__init__()\n",
    "        self.layer_all = [layer(num) for num in layer_unit]\n",
    "    def forward(self, x):\n",
    "        for l in self.layer_all:\n",
    "            print(x.shape)\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "class HSML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HSML, self).__init__()\n",
    "        self.cluster = clustering()\n",
    "        self.rnn = RNN_AE(hidden_size=20)\n",
    "    def forward(self, x):\n",
    "        recon, z, target,output = self.rnn(x)\n",
    "        mseloss = nn.MSELoss()(recon, target)\n",
    "        cluster_result = self.cluster(z[0].unsqueeze(dim=1))\n",
    "        cluster_result = cluster_result.squeeze(dim = 1)#batch*20\n",
    "        gate = torch.cat([z[0],cluster_result], dim = -1)\n",
    "        return gate, mseloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 20])\n",
      "torch.Size([20, 4, 20])\n",
      "torch.Size([20, 2, 20])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
